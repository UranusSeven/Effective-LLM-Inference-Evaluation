# Effective LLM Inference Evaluation
Effective LLM Inference Evaluation is a project aimed at measuring the real-world performance of Large Language Model (LLM) inference frameworks, inspired by the concepts in [deepspeed-fastgen](https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-fastgen/README.md#4-performance-evaluation--).
